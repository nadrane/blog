{"data":{"allMarkdownRemark":{"totalCount":12,"edges":[{"node":{"excerpt":"Two months ago I purchased a GPS device and associated service plan from  SPOT . Today, upon trying to cancel the service, the customer service representative informed me that I had accidentally enrolled myself into a 1 year, $250 contract and that I was unable to cancel. He told me that if I blocked the monthly charges against my credit card that they would report the debt to a collections agency. I was initially upset but soon realized it was a great opportunity to talk about ethics in software engineering. SPOT's Marketing Materials The representative told me to look at their website where he claimed it would be very clear that I was signing up for a contract service. When I Googled \"spot service plan\", the first link I clicked on directed me to these marketing materials: If you look at the image above, it appears as if several deliberate decisions have been made to disguise the total cost of the month-to-month arrangement. The font of the month-to-month price is large, bold, and…","slug":"ethical-engineering-for-the-average-engineer","frontmatter":{"title":"Ethical Engineering for the Average Engineer","date":"2018-09-16T15:41:16.000Z"}}},{"node":{"excerpt":"I stumbled upon an  article  the other day where Rob Pike implements a rudimentary regular expression engine in c. I converted his code to Javascript and added test specs so that someone can self-guide themselves through the creation of the regex engine. The specs and solution can be found in this  GitHub repository . This blog post walks through my solution. The Problem Our regex engine will support the following syntax: Syntax Meaning Example matches a Matches the specified character literal q q * Matches 0 or more of the previous character a * \"\", a, aa, aaa ? Matches 0 or 1 of the previous character a? \"\", a . Matches any character literal . a, b, c, d, e ... ^ Matches the start of a string ^c c, ca, caa, cbb ... $ Matches the end of a string a$ ba, baaa, qwerta ... The goal is to provide a syntax robust enough to match a large portion of regex use cases with minimal code. Matching One Character The first step is to write a function that takes in a one character pattern and a one…","slug":"build-your-own-regex","frontmatter":{"title":"Build a Regex Engine in Less than 40 Lines of Code","date":"2017-11-28T11:36:04.000Z"}}},{"node":{"excerpt":"The other day at work, one of my colleagues was frustrated that he was unable to encode nested objects in a query string and still maintain a readable URL. I went home that night and coded up a simple solution to this problem, and I thought I'd share it here today. This  Github repo  contains specs and the solution code. Motivation Today, in the Node.js ecosystem, numerous modules exist to encode query strings, but they generally have one of two flaws: They do not permit the encoding of nested objects. They can encode nested objects, but they delimit nesting using unsafe URL characters, yielding an operation and a result that look like this  1 : The Problem in Detail Node.js provides a   module to encode objects to query strings. The only problem is that conforms to an official specification that doesn't allow nested objects. Unfortunately, this specification does not allow for enough flexibility when creating a RESTful API. For example, suppose the client wants to filter a collection…","slug":"build-your-own-nested-query-string-encoder","frontmatter":{"title":"Build Your Own Nested Query String Encoder/Decoder","date":"2018-04-13T15:17:00.000Z"}}},{"node":{"excerpt":"Postgres  introduced the  JSONB  type in version 9.4 with considerable excitement. JSONB promised to marry a favorite relational database with the noSQL world, permitting data to be stored in the database as JSON without the need for re-parsing whenever a field is accessed. Moreover, the binary storage format permits indexing and complex queries against the stored JSON blobs. This data format embodies the flexible schema and was readily adopted at  Fraight . Background At Fraight, we've built a centralized communication platform that collates all inbound/outbound communications between our brokerage company and thousands of trucking partners. One of our main objectives is to build a system that parses and automatically responds to inbound text messages, emails, and faxes. We knew we would eventually need the nitty-gritty details of these messages, so we captured the data by dumping entire http response bodies into a JSONB column named   in our database’s   table. In an ideal world, the…","slug":"hidden-costs-of-postgresql-jsonb","frontmatter":{"title":"The Hidden Costs of PostgreSQL's JSONB Datatype","date":"2018-09-30T00:00:00.000Z"}}},{"node":{"excerpt":"A client approached me with a puzzling problem: At Fraight, we have an omnisearch interface backed by an Elasticsearch datastore. The interface allows users yo type a freetext query and get a list of database records sorted by relevancy. At it's core, this is a simple problem: if the user types in  , return all people whose name contains the word  . And indeed, returning all the   in the system is trivial; the problem is that we worked hundreds, possibly even thousands of  . How do we identify the particular   that we care about? A Poor Solution When I worked at  Epic , we had a similar problem. We had a search interface that allowed us to look up patients. Unfortunately, our full names are not as unique as we like to believe, and a simple query for   would surely bring the system to a halt. Epic solved this problem by providing additional fields. That's why (along with HIPPA reasons), when you call the doctor, they might ask for your birthdate or your address; this additional…","slug":"optimizing-elasticsearch-score","frontmatter":{"title":"Optimizing Elasticsearch Score: How to Rank and Differentiate Similar Records","date":"2017-10-11T00:00:00.000Z"}}},{"node":{"excerpt":"I posted my article  Build Your Own Regex Engine  on Reddit the other day, and one of the commenters claimed that the implementation should be trivial to break. Since I had already tested my program against a customized suite of tests, the remark got me thinking about how I could further increase my confidence in the correctness of my program. One extremely low cost however effective strategy for identifying faults in software is known as fuzzing. What is Fuzzing? Fuzzing is a automated testing technique where a program is provided a series of invalid or randomly generated inputs. If we were testing an HTTP API, we might send randomized combinations of query parameters and ensure that our server always returns a 2xx status code. Since Javascript comes with a regular expression engine, my fuzzer asserts that given the same random input, both engine's return the same output. Specifying the Grammar The first step is to specify the grammar that our regex engine supports. You might notice…","slug":"regex-and-automated-test-fuzzing","frontmatter":{"title":"Regex And Automated Test Fuzzing","date":"2017-12-06T00:00:00.000Z"}}},{"node":{"excerpt":"React has taken the web development community by a storm, and with it functional programming concepts have embedded themselves in the mainstream. One common statement you will often read is that all state in React should be immutable, and this practice is justified as necessary for performance reasons. This statement is entirely true, but it only tells half the truth. Immutability alone will not yield any performance gains in React (it'll actually make things slower). The Quick Answer You can reap the gains from immutable state in React if you inherit from  React.PureComponent  instead of  A Broader Perspective So why does the above code work? That requires a little bit of knowledge about the rendering process. Virtual DOM A component's   function returns a tree of React elements, also known as the virtual DOM. This data structure is a representation of the browser's DOM that React can manipulate in a performant way. In essence, it's a 1-1 mapping to the browser DOM. Whenever state or…","slug":"leveraging-immutability-in-react","frontmatter":{"title":"Leveraging Immutability in React","date":"2017-09-27T09:30:27.000Z"}}},{"node":{"excerpt":"I'm currently contracted to create a web service using some data from a third party Angular application. I worked off a proof of concept codebase that used Chrome's new  Puppeteer  API to scrape this site. I strongly regret not starting from scratch. What is Puppeteer? Puppeteer is a Node API that allows you to control Google's headless Chrome browser. Imagine a version of your browser that can send and receive requests but has no GUI. It works in the background, performing actions as instructed by an API. This makes Puppeteer great for end to end testing a web application. You can truly simulate the user experience, typing where they type and clicking where they click. Another use case for Puppeteer is web scraping a single page web application. Let's explore how this might work. A Simple Example For any Puppeteer project, the first task is to create an instance of the headless browser. After that's done, it's trivial to navigate to and begin interacting with a webpage. Let's suppose…","slug":"scraping-the-web-with-puppeteer-lessons-learned","frontmatter":{"title":"Scraping the Web with Puppeteer: Lessons Learned","date":"2017-12-09T15:35:13.000Z"}}},{"node":{"excerpt":"I've conducted about 100 technical interviews over the past 6 months for a software development recruiting company called  Triplebyte . I've also been doing consulting work, which has required me to take numerous technical interviews. It's interesting contrasting the experiences to identify what works and what doesn't. Every Triplebyte interview begins with the candidate coding a short game. We have a series of steps, and each step precisely defines simple requirements for the program to handle. I can generally tell a couple minutes into the 2 hour interview whether the candidate will be successful. There are certainly outliers (as well as mechanisms to prevent bias), but in general, I can quickly ascertain how well a candidate stacks up technically. So then, it begs the question, why is it so hard to hire engineers? The answer is, most of us are doing it wrong. Interview Standardization About 12 months ago, while running  Fullstack Academy's  Chicago campus, I was looking to hire a…","slug":"you're-hiring-programmers-wrong-a-case-for-interview-standardization","frontmatter":{"title":"You're Hiring Programmers Wrong: A Case for Interview Standardization","date":"2018-03-20T17:03:01.000Z"}}},{"node":{"excerpt":"I recently wanted to ingest a  line-delimited  JSON file into  Postgres  for some quick data exploration. I was surprised when I couldn't find a simple CLI solution that parsed the JSON and loaded each field into its own column. Every approach I found instead inserted the entire JSON object in a JSONB field. Here is my solution. Downloading 250000 Hacker News Comments Let's say we want to download all of the  Hacker News  comments from the month of May. A line-delimited JSON file is available from  pushshift . Fetching and decompressing the file is simple: Here is what the dataset looks like: Formatting the Data You might think that Postgres has a simple utility for loading line-delimited JSON. Like me, you'd be wrong. It's all the more surprising given that it has a  COPY  utility that's designed to load data from files. Unfortunately, that utility only supports  ,  , and   formats. Transforming our data into a CSV is a breeze with  jq . We can pipe the JSON stream into the following…","slug":"using-jq-to-effortlessly-ingest-newline-delimited-JSON-into-postgres","frontmatter":{"title":"Using Shell Commands to Effortlessly Ingest Line-delimited JSON into PostgreSQL","date":"2018-10-18T00:00:00.000Z"}}},{"node":{"excerpt":"My inspiration for this blog post came from  this video  where Dan Abramov walks through the source code to react-redux As frontend web developers, it's not uncommon that we follow well-specified patterns - often blindly. The frontend landscape is changing rapidly, and sometimes there isn't time to investigate why we use a specific pattern; we just know we should. One widely used pattern in  react-redux  applications looks like this I'll assume you know how to implement this pattern, but why do we use it and how does it work under the hood? Why Do we Need React-Redux? React and Redux are two completely independent tools that have nothing to do with each other. React is a tool for creating user interfaces in the browser. Redux is a tool for managing state. Either tool can be used without the other. We often use them together because they both solve separate but very important and closely related problems. The purpose of react-redux is to get these two tools to talk. But first, what…","slug":"write-your-own-redux-connect","frontmatter":{"title":"Write Your Own React-Redux Connect","date":"2017-09-29T13:14:18.000Z"}}},{"node":{"excerpt":"My first introduction to functional programming was a couple years ago when I read through the famous  SICP . As someone who had up to this point worked with mostly in object oriented and imperative languages, I had rarely seen  ,  , and   before that time. The purpose of the former two felt obvious; the latter one not so much. This blog post is geared for someone who knows how   works but feels like they struggle to use it practically. Reduce Basics Feel free to skip this section if you understand the basics of reduce Reduce  is known as a higher order function (HOF). A HOF is defined as a function that either takes in or returns another function. Reduce takes two parameters: the first is a function, and the second is known as the initial accumulator. We will invoke this function over every element of an array. The ultimate goal is to transform the array into something new. Suppose we want to take an array of characters and concatenate them into a single string. In this example, the…","slug":"using-reduce","frontmatter":{"title":"Using Reduce","date":"2017-09-28T10:36:30.000Z"}}}]}},"pageContext":{}}